# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1huDgMsM1P_Y9XfktZBFUOxOE6GhNDMs_
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Zomato Dataset.csv')

df.head()

df.columns

# Lowering all the columns so there is no typo while mentioning column names
df.columns = [col.lower() for col in df.columns]

df.rename(columns = {"time_taken (min)" : "time_taken_min"},inplace = True)
df

df.info()

# Change data types of columns order_date to datetime
df['order_date'] = pd.to_datetime(df["order_date"],format="%d-%m-%Y")
df.info()

# Checking null values
(df.isnull().sum()/len(df)) * 100

# Drop the missing values
df.dropna(inplace = True)
(df.isnull().sum()/len(df)) * 100

df.duplicated().sum()

# Convert order_date to datetime and extract month
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
df['order_month'] = df['order_date'].dt.strftime('%b')

#Creating new feature for age bins for further analysis
age_bins = [20, 25, 30, 35, 40]
age_labels = ["20-24", "25-29", "30-34", "35+"]

df['age_bins'] = pd.cut(
    df['delivery_person_age'],
    bins=age_bins,
    labels=age_labels,
    right=False
)

#We create a binary feature indicating whether an order was placed during peak hours.
#Peak hours defined as:
#Lunch: 11 AM – 2 PM
#Evening: 5 PM – 9 PM

df['time_orderd'] = pd.to_datetime(df['time_orderd'], format='%H:%M', errors='coerce')
def is_peak_hour(df):
  hour= pd.to_datetime(df['time_orderd']).hour
  return 1 if (11 <= hour < 14) or (17 <= hour < 21) else 0
df['peak_hours'] = df.apply(is_peak_hour, axis=1)

df.head()

Q1 = df['time_taken_min'].quantile(0.25)
Q3 = df['time_taken_min'].quantile(0.75)

IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

lower_bound, upper_bound

#Visualize Outliers (Before Removal)
plt.figure()
plt.boxplot(df['time_taken_min'])
plt.ylabel('Delivery Time (minutes)')
plt.title('Delivery Time Before Outlier Removal')
plt.show()

outliers = df[
    (df['time_taken_min'] < lower_bound) |
    (df['time_taken_min'] > upper_bound)
]

outliers.shape

df_clean = df[
    (df['time_taken_min'] >= lower_bound) &
    (df['time_taken_min'] <= upper_bound)
]

print("Original data size:", df.shape)
print("After outlier removal:", df_clean.shape)

#performed outlier detection on the delivery time using the IQR method. The calculated bounds were
#−2 and 54 minutes, and all data points fell within this range. This indicates that the dataset does not contain extreme
#delivery time values. Therefore, no records were removed,
#and the data was retained as-is.

#Bar plot comparing average delivery times across different weather condition.

plt.figure(figsize =(10,6))
ax = sns.barplot(x="weather_conditions", y="time_taken_min", data=df,color="#E23744")

# Add bar labels
for container in ax.containers:
    ax.bar_label(container)

# Show the plot
plt.title("Average Delivery Times across diffrent Weather Condition")
plt.xlabel("Weather condition")
plt.ylabel("Time Taken (minutes)")
plt.show()

#Bar plot comparing average delivery times depending upon Festival.

plt.figure(figsize =(10,6))
ax = sns.barplot(x="festival", y="time_taken_min", data=df,color="#E23744")

# Add bar labels
for container in ax.containers:
    ax.bar_label(container)

# Show the plot
plt.title("Average Delivery Times depending upon Festival")
plt.xlabel("Festival")
plt.ylabel("Time Taken (minutes)")
plt.show()

#Bar plot comparing average delivery times across different vehicle types and Peak Hours.

plt.figure(figsize =(10,6))
ax = sns.barplot(x="type_of_vehicle", y="time_taken_min",hue="peak_hours", data=df,color="#E23744")

# Add bar labels
for container in ax.containers:
    ax.bar_label(container)

# Show the plot
plt.title("Average Delivery Times by Vehicle Type and peak hours")
plt.xlabel("Type of Vehicle")
plt.ylabel("Time Taken (minutes)")
plt.legend(title = "Peak Hours")
plt.show()

#Delivery times increase during peak hours across all vehicle types.
#Electric scooters have the shortest delivery time (22.11 minutes) during non-peak hours but see a larger increase
# (to 26.71 minutes) during peak hours compared to motorcycles and scooters.

#relationship between the density of road traffic and delivery delays?
plt.figure(figsize=(10, 6))
sns.boxplot(x='road_traffic_density', y='time_taken_min', data=df,color="#E23744")
plt.title('Delivery Time by Road Traffic Density')
plt.xlabel('Road Traffic Density')
plt.ylabel('Time Taken (min)')
plt.show()

#Bar plot comparing average delivery times across different City.

plt.figure(figsize =(10,6))
ax = sns.barplot(x="city", y="time_taken_min", data=df,color="#E23744")

# Add bar labels
for container in ax.containers:
    ax.bar_label(container)

# Show the plot
plt.title("Average Delivery Times across diffrent City")
plt.xlabel("City")
plt.ylabel("Time Taken (minutes)")
plt.show()

#Semi-urban areas have the longest average delivery times (49.37 minutes),
#While urban areas have the shortest (23.03 minutes).
#Metropolitan areas fall in between (27.11 minutes).

#How does the age of the delivery person affect delivery performance?
plt.figure(figsize=(12, 6))
ax = sns.barplot(x="age_bins", y="time_taken_min",  data=df,color="#E23744")
for container in ax.containers:
    ax.bar_label(container)
plt.title("Delivery Time by Age Bins")
plt.xlabel("Age Bins")
plt.ylabel("Time Taken (min)")
plt.show()

#The average delivery time increases with age, peaking in the 30-34 age group (29.32 minutes), suggesting that older customers
#might experience longer wait times. While 20-24 age group has less delivery time.

#How do average delivery times differ between peak hours and off-peak hours?
plt.figure(figsize =(10,6))
ax = sns.barplot(x="peak_hours", y="time_taken_min", data=df,color = "#E23744")

# Add bar labels
for container in ax.containers:
    ax.bar_label(container)

# Show the plot
plt.title("Average Delivery Times depending upon peak_hours")
plt.xlabel("peak_hours")
plt.ylabel("Time Taken (minutes)")
plt.show()

#Scatter plot comparing average delivery times VS Delivery Person Rating.

plt.figure(figsize=(10, 6))
sns.scatterplot(x="delivery_person_ratings", y="time_taken_min", data=df,color="#E23744")
plt.title("Delivery Person Ratings vs. Time Taken for Delivery")
plt.xlabel("Delivery Person Ratings")
plt.ylabel("Time Taken (min)")
plt.show()

numeric_columns = df.select_dtypes(include=["number"])
# Using heatmap to view correlation
plt.figure(figsize = (10,6))
sns.heatmap(numeric_columns.corr(), cmap='cool', annot=True, fmt='.2f', square=True)
plt.title('Correlation Heatmap')
plt.show()

### derive distance between restaurant & delivery location ###
from sklearn.metrics.pairwise import haversine_distances
coords_rest = np.radians(df[['restaurant_latitude', 'restaurant_longitude']])
coords_del = np.radians(df[['delivery_location_latitude', 'delivery_location_longitude']])

df['distance_km'] = np.diag(haversine_distances(coords_rest, coords_del)) * 6371

X = df.drop(columns=['time_taken_min', 'id'])
y = df['time_taken_min']

#Pickup time is not known at order placement, so using it inflates accuracy unrealistically.
X = X.drop(columns=['time_order_picked'])

cat_cols = X.select_dtypes(include='object').columns

X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)

X_encoded

# Separate target
X = df.drop(columns=['time_taken_min', 'id', 'time_order_picked'])
y = df['time_taken_min']

# Encode categoricals
cat_cols = X.select_dtypes(include='object').columns
X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)

X_encoded.select_dtypes(include=['object', 'category']).columns

for col in X_encoded.select_dtypes(include=['object', 'category']).columns:
    print(col)
    print(X_encoded[col].unique())
    print("-" * 30)

cat_cols = X.select_dtypes(exclude=['int64', 'float64']).columns

X_encoded = pd.get_dummies(
    X,
    columns=cat_cols,
    drop_first=True
)

# There should be NO object or category columns left
X_encoded.select_dtypes(include=['object', 'category'])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

lr = LinearRegression()
lr.fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)

lr_mae = mean_absolute_error(y_test, y_pred_lr)
lr_r2 = r2_score(y_test, y_pred_lr)

print("Linear Regression MAE:", lr_mae)
print("Linear Regression R2:", lr_r2)

rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=12,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1
)

rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

rf_mae = mean_absolute_error(y_test, y_pred_rf)
rf_r2 = r2_score(y_test, y_pred_rf)

print("Random Forest MAE:", rf_mae)
print("Random Forest R2:", rf_r2)

from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=3,
    random_state=42
)

gbr.fit(X_train, y_train)

y_pred_gbr = gbr.predict(X_test)

print("GB MAE:", mean_absolute_error(y_test, y_pred_gbr))
print("GB R2:", r2_score(y_test, y_pred_gbr))

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, r2_score

ridge = Ridge(alpha=1.0, random_state=42)
ridge.fit(X_train, y_train)

y_pred_ridge = ridge.predict(X_test)

ridge_mae = mean_absolute_error(y_test, y_pred_ridge)
ridge_r2 = r2_score(y_test, y_pred_ridge)

print("Ridge MAE:", ridge_mae)
print("Ridge R2:", ridge_r2)

from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.01, max_iter=5000, random_state=42)
lasso.fit(X_train, y_train)

y_pred_lasso = lasso.predict(X_test)

lasso_mae = mean_absolute_error(y_test, y_pred_lasso)
lasso_r2 = r2_score(y_test, y_pred_lasso)

print("Lasso MAE:", lasso_mae)
print("Lasso R2:", lasso_r2)

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(
    random_state=42,
    n_jobs=-1
)

param_dist = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}

random_rf = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=20,
    scoring='neg_mean_absolute_error',
    cv=3,
    n_jobs=-1,
    random_state=42
)

random_rf.fit(X_train, y_train)

best_rf = random_rf.best_estimator_

print("Best RF Params:", random_rf.best_params_)

from sklearn.metrics import mean_absolute_error, r2_score

# Predict on test data
y_pred = best_rf.predict(X_test)

# Evaluate
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Tuned RF MAE:", mae)
print("Tuned RF R2:", r2)

import pickle

with open('best_rf_model.pkl', 'wb') as f:
    pickle.dump(best_rf, f)

print("Tuned Random Forest saved as 'best_rf_model.pkl'")